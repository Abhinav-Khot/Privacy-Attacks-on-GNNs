{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from models.gcn import GCN, embedding_GCN\n",
    "from models.DPAR import DPAR\n",
    "from topology_attack import PGDAttack\n",
    "from utils import *\n",
    "from dataset import Dataset\n",
    "import argparse\n",
    "from sklearn.metrics import roc_curve, auc, average_precision_score\n",
    "import scipy.io as sio\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# def test(adj, features, labels, victim_model):\n",
    "#     adj, features, labels = to_tensor(adj, features, labels, device=device)\n",
    "\n",
    "#     victim_model.eval()\n",
    "#     adj_norm = normalize_adj_tensor(adj)\n",
    "#     output = victim_model(features, adj_norm)\n",
    "\n",
    "#     loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "#     acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "#     print(\"Test set results:\", \"loss= {:.4f}\".format(loss_test.item()), \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "\n",
    "    # return output.detach()\n",
    "\n",
    "def dot_product_decode(Z):\n",
    "    Z = F.normalize(Z, p=2, dim=1)\n",
    "    Z = torch.matmul(Z, Z.t())\n",
    "    adj = torch.relu(Z-torch.eye(Z.shape[0]))\n",
    "    return adj\n",
    "\n",
    "def preprocess_Adj(adj, feature_adj):\n",
    "    n=len(adj)\n",
    "    cnt=0\n",
    "    adj=adj.numpy()\n",
    "    feature_adj=feature_adj.numpy()\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if feature_adj[i][j]>0.14 and adj[i][j]==0.0:\n",
    "                adj[i][j]=1.0\n",
    "                cnt+=1\n",
    "    print(cnt)\n",
    "    return torch.FloatTensor(adj)\n",
    "\n",
    "def transfer_state_dict(pretrained_dict, model_dict):\n",
    "    state_dict = {}\n",
    "    for k, v in pretrained_dict.items():\n",
    "        if k in model_dict.keys():\n",
    "            state_dict[k] = v\n",
    "        else:\n",
    "            print(\"Missing key(s) in state_dict :{}\".format(k))\n",
    "    return state_dict\n",
    "\n",
    "def metric(ori_adj, inference_adj, idx):\n",
    "    real_edge = ori_adj[idx, :][:, idx].reshape(-1)\n",
    "    pred_edge = inference_adj[idx, :][:, idx].reshape(-1)\n",
    "    # real_edge = ori_adj.reshape(-1)\n",
    "    # pred_edge = inference_adj.reshape(-1)\n",
    "    fpr, tpr, threshold = roc_curve(real_edge, pred_edge)\n",
    "    index = np.where(real_edge == 0)[0]\n",
    "    index_delete = np.random.choice(index, size=int(len(real_edge)-2*np.sum(real_edge)), replace=False)\n",
    "    real_edge = np.delete(real_edge, index_delete)\n",
    "    pred_edge = np.delete(pred_edge, index_delete)\n",
    "    print(\"Inference attack AUC: %f AP: %f\" % (auc(fpr, tpr), average_precision_score(real_edge, pred_edge)))\n",
    "    #get the  number of edges predicted correctly\n",
    "    #correct_edges = number of edges in which both real and predicted edge values are 1\n",
    "    correct_edges = np.sum((real_edge == 1) & (pred_edge == 1))\n",
    "    pcnt = correct_edges/np.sum(real_edge == 1)\n",
    "    print(\"Number of edges predicted correctly:\", correct_edges, pcnt)\n",
    "\n",
    "\n",
    "def Auc(ori_adj, modified_adj, idx):\n",
    "    real_edge = []\n",
    "    pred_edge = []\n",
    "    for i in idx:\n",
    "        for j in idx:\n",
    "            if i != j:\n",
    "                real_edge.append(ori_adj[i][j])\n",
    "                pred_edge.append(modified_adj[i][j])\n",
    "                #pred_edge.append(np.dot(output[idx[i]], output[idx[j]])/(np.linalg.norm(output[idx[i]])*np.linalg.norm(output[idx[j]])))\n",
    "                #pred_edge.append(-np.linalg.norm(output[idx[i]]-output[idx[j]]))\n",
    "                #pred_edge.append(np.dot(features[idx[i]], features[idx[j]]) / (np.linalg.norm(features[idx[i]]) * np.linalg.norm(features[idx[j]])))\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(real_edge, pred_edge)\n",
    "    print(auc(fpr, tpr))\n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=15, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='Number of epochs to optimize in GraphMI attack.')\n",
    "parser.add_argument('--lr', type=float, default=0.01,\n",
    "                    help='Initial learning rate.')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4,\n",
    "                    help='Weight decay (L2 loss on parameters).')\n",
    "parser.add_argument('--hidden', type=int, default=16,\n",
    "                    help='Number of hidden units.')\n",
    "parser.add_argument('--dropout', type=float, default=0.5,\n",
    "                    help='Dropout rate (1 - keep probability).')\n",
    "parser.add_argument('--dataset', type=str, default='cora',\n",
    "                    choices=['cora', 'cora_ml', 'citeseer', 'polblogs', 'pubmed', 'AIDS', 'usair', 'brazil'], help='dataset')\n",
    "parser.add_argument('--density', type=float, default=1.0, help='Edge density estimation')\n",
    "parser.add_argument('--model', type=str, default='PGD', choices=['PGD', 'min-max'], help='model variant')\n",
    "parser.add_argument('--nlabel', type=float, default=0.1)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "device = torch.device(\"cpu\") #comment this later after fixing tensor device issues\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if device != 'cpu':\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "# data = Dataset(root='', name=args.dataset, setting='GCN')\n",
    "# adj, features, labels, init_adj = data.adj, data.features, data.labels, data.init_adj\n",
    "\n",
    "# idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "#choose the target nodes\n",
    "\n",
    "b = np.load('matricx.npz', allow_pickle = True)\n",
    "\n",
    "adj = torch.from_numpy(b[\"train_adj_matrix\"])\n",
    "features = torch.from_numpy(b[\"train_attr_matrix\"])\n",
    "labels = b[\"train_labels\"]\n",
    "# print(type(adj))\n",
    "n = adj.shape[0]\n",
    "result = np.zeros((n, n))\n",
    "init_adj = sp.csr_matrix(result)\n",
    "\n",
    "print('Done')\n",
    "\n",
    "idx_attack = np.array(random.sample(range(adj.shape[0]), int(adj.shape[0]*args.nlabel)))\n",
    "print(f\"Number of indices randomly selected: {len(idx_attack)}\")\n",
    "# idx_attack = np.array(range(adj.shape[0]))\n",
    "print(idx_attack)\n",
    "num_edges = int(0.5 * args.density * adj.sum()/adj.shape[0]**2 * len(idx_attack)**2)\n",
    "\n",
    "adj, features, labels = preprocess((adj), features, labels, preprocess_adj=False, onehot_feature=False)\n",
    "# to tensor\n",
    "print(len(labels))\n",
    "feature_adj = dot_product_decode(features)\n",
    "preprocess_adj = preprocess_Adj(adj, feature_adj)\n",
    "init_adj = torch.FloatTensor(init_adj.todense())\n",
    "# initial adj is set to zero matrix\n",
    "\n",
    "loaded_params = np.load('model_cora_ml_sampling50pct.npz', allow_pickle=True)\n",
    "print(loaded_params['W1:0'].shape)\n",
    "print(loaded_params['W2:0'].shape)\n",
    "victim_model = DPAR(loaded_params)\n",
    "\n",
    "# Setup Victim Model\n",
    "\n",
    "# victim_model = GCN(nfeat=features.shape[1], nclass=labels.max().item() + 1, nhid=16,\n",
    "#                    dropout=0.5, weight_decay=5e-4, device=device)\n",
    "\n",
    "# victim_model = victim_model.to(device)\n",
    "# victim_model.fit(features, adj, labels, idx_train, idx_val)\n",
    "\n",
    "# embedding = embedding_GCN(nfeat=features.shape[1], nhid=16, device=device)\n",
    "# embedding.load_state_dict(transfer_state_dict(victim_model.state_dict(), embedding.state_dict()))\n",
    "\n",
    "# Setup Attack Model\n",
    "\n",
    "model = PGDAttack(model=victim_model, nnodes=adj.shape[0], loss_type='CE', device=device)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "model.attack(features, init_adj, labels, idx_attack, num_edges, epochs=args.epochs)\n",
    "inference_adj = model.modified_adj.cpu()\n",
    "# print('=== testing GCN on original(clean) graph ===')\n",
    "# test(adj, features, labels, victim_model)\n",
    "print('=== calculating link inference AUC&AP ===')\n",
    "print(inference_adj.numpy().sum(axis = 0))\n",
    "print(torch.max(inference_adj), torch.min(inference_adj))\n",
    "metric(adj.numpy(), inference_adj.numpy(), idx_attack)\n",
    "\n",
    "#output = embedding(features.to(device), torch.zeros(adj.shape[0], adj.shape[0]).to(device))\n",
    "#adj1 = dot_product_decode(output.cpu())\n",
    "#metric(adj.numpy(), adj1.detach().numpy(), idx_attack)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
